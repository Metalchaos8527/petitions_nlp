{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA weights 다시 생성하기\n",
    "#LDA에 모든 데이터를 넣고 그 데이터로 train,test 데이터를 나누기\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_pickle('df_noun_2018_re2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>mod_content</th>\n",
       "      <th>num_agree</th>\n",
       "      <th>new_status</th>\n",
       "      <th>mod_begin</th>\n",
       "      <th>cont_noun</th>\n",
       "      <th>cont_noun_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>행정</td>\n",
       "      <td>아...이런데서 이상한 글이 올라오네요...</td>\n",
       "      <td>국민청원하는 게시판에서 뭐 섹스,희주야이런 이상한 글 올라오는데 여기는 청원하는데지...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>[국민, 청원, 게시판, 섹스, 희, 주야, 글, 청원, 곳, 놈, 처벌, 글]</td>\n",
       "      <td>국민,청원,게시판,섹스,희,주야,글,청원,곳,놈,처벌,글</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기타</td>\n",
       "      <td>현재 사람들 사이에서 유행하는 게임 \"배틀 그라운드\" 에 대한 제재를 가하려 합니다.</td>\n",
       "      <td>배틀 그라운드는 현재 세계적으로나 우리나라 에서나 매우 흥행 하는 게임입니다. 게임...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>[배틀, 그라운드, 세계, 나라, 흥행, 게임, 게임, 청소년, 이용, 불가, 게임...</td>\n",
       "      <td>배틀,그라운드,세계,나라,흥행,게임,게임,청소년,이용,불가,게임,표,피시방,청소년,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>정치개혁</td>\n",
       "      <td>양심수 석방 국가보안법 철폐</td>\n",
       "      <td>적폐청산의 시금석 양심수들의 특별사면 배제 문재인 정부를 규탄한다. 지난 문재인 정...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>[적폐, 청산, 시금석, 양심수, 특별, 사면, 배제, 문재, 정부, 규탄, 문재,...</td>\n",
       "      <td>적폐,청산,시금석,양심수,특별,사면,배제,문재,정부,규탄,문재,정부,특별,사면,단행...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>인권/성평등</td>\n",
       "      <td>민주화유공자들에 대한 국가유공자 인정 요청</td>\n",
       "      <td>안녕하세요. 살벌한 독재시대를 떠나, 대한민국 민주화를 이룩하신 수많은 열사들이, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>[안녕, 독재, 시대, 대한민국, 민주, 열사, 민주, 유공자, 인정, 국가, 유공...</td>\n",
       "      <td>안녕,독재,시대,대한민국,민주,열사,민주,유공자,인정,국가,유공자,인정,이야기,청원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>외교/통일/국방</td>\n",
       "      <td>UAE 관련</td>\n",
       "      <td>Uae 괸련한 야당 질의와 관련하여 기본적으로 유시민 작가의 말씀에 동의하여 국익에...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>[련, 야당, 질의, 관련, 기본, 유시민, 작가, 말씀, 동의, 국익, 관련, 정...</td>\n",
       "      <td>련,야당,질의,관련,기본,유시민,작가,말씀,동의,국익,관련,정부,문재,정부,참고,야...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                            title  \\\n",
       "0        행정                         아...이런데서 이상한 글이 올라오네요...   \n",
       "1        기타  현재 사람들 사이에서 유행하는 게임 \"배틀 그라운드\" 에 대한 제재를 가하려 합니다.   \n",
       "2      정치개혁                                  양심수 석방 국가보안법 철폐   \n",
       "3    인권/성평등                          민주화유공자들에 대한 국가유공자 인정 요청   \n",
       "4  외교/통일/국방                                           UAE 관련   \n",
       "\n",
       "                                         mod_content  num_agree  new_status  \\\n",
       "0  국민청원하는 게시판에서 뭐 섹스,희주야이런 이상한 글 올라오는데 여기는 청원하는데지...          6           0   \n",
       "1  배틀 그라운드는 현재 세계적으로나 우리나라 에서나 매우 흥행 하는 게임입니다. 게임...          1           0   \n",
       "2  적폐청산의 시금석 양심수들의 특별사면 배제 문재인 정부를 규탄한다. 지난 문재인 정...          0           0   \n",
       "3  안녕하세요. 살벌한 독재시대를 떠나, 대한민국 민주화를 이룩하신 수많은 열사들이, ...          3           0   \n",
       "4  Uae 괸련한 야당 질의와 관련하여 기본적으로 유시민 작가의 말씀에 동의하여 국익에...          0           0   \n",
       "\n",
       "   mod_begin                                          cont_noun  \\\n",
       "0 2018-01-01       [국민, 청원, 게시판, 섹스, 희, 주야, 글, 청원, 곳, 놈, 처벌, 글]   \n",
       "1 2018-01-01  [배틀, 그라운드, 세계, 나라, 흥행, 게임, 게임, 청소년, 이용, 불가, 게임...   \n",
       "2 2018-01-01  [적폐, 청산, 시금석, 양심수, 특별, 사면, 배제, 문재, 정부, 규탄, 문재,...   \n",
       "3 2018-01-01  [안녕, 독재, 시대, 대한민국, 민주, 열사, 민주, 유공자, 인정, 국가, 유공...   \n",
       "4 2018-01-01  [련, 야당, 질의, 관련, 기본, 유시민, 작가, 말씀, 동의, 국익, 관련, 정...   \n",
       "\n",
       "                                       cont_noun_str  \n",
       "0                    국민,청원,게시판,섹스,희,주야,글,청원,곳,놈,처벌,글  \n",
       "1  배틀,그라운드,세계,나라,흥행,게임,게임,청소년,이용,불가,게임,표,피시방,청소년,...  \n",
       "2  적폐,청산,시금석,양심수,특별,사면,배제,문재,정부,규탄,문재,정부,특별,사면,단행...  \n",
       "3  안녕,독재,시대,대한민국,민주,열사,민주,유공자,인정,국가,유공자,인정,이야기,청원...  \n",
       "4  련,야당,질의,관련,기본,유시민,작가,말씀,동의,국익,관련,정부,문재,정부,참고,야...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 2000, max_df = 0.80, min_df = 5).fit(df['cont_noun_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_array = cv.transform(df['cont_noun_str']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37\n"
     ]
    }
   ],
   "source": [
    "print(np.round((now2 - now) / 60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간: -3.24\n"
     ]
    }
   ],
   "source": [
    "#토필모델링 가중치 데이터 생성\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "topic_num = 11\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "sk_lda = LatentDirichletAllocation(n_components = topic_num, n_jobs = -1)\n",
    "sk_lda_f = sk_lda.fit(cv_array)\n",
    "print('소요시간:', np.round((start - time.time()) / 60, 2))\n",
    "    #n_jobs =-1 옵션을 썻더니 소요시간이 많이 단축됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_weights = sk_lda_f.transform(cv_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269242, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_weights.shape\n",
    "    #26만개의 단어들이 11개의 토픽에 속할 확률을 나탄내는 행렬 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lda_weights, df['category'],\n",
    "                                                   test_size = 0.3, random_state = 156,\n",
    "                                                   stratify = df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤포레스트로 학습시도\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=156)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state = 156, n_jobs = -1)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA weights이용 랜덤포레스트 정확도: 0.34167357904250184\n"
     ]
    }
   ],
   "source": [
    "pred = rf_clf.predict(X_test)\n",
    "print('LDA weights이용 랜덤포레스트 정확도:', accuracy_score(y_test, pred))\n",
    "    #정확도가 더욱 하락됨..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간: 3.53\n"
     ]
    }
   ],
   "source": [
    "#토픽개수를 8개로 설정해보고 시도해보기\n",
    "topic_num = 8\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "sk_lda = LatentDirichletAllocation(n_components = topic_num, n_jobs = -1)\n",
    "sk_lda_f = sk_lda.fit(cv_array)\n",
    "print('소요시간:', np.round((time.time() - start) / 60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_weights2 = sk_lda_f.transform(cv_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lda_weights2, df['category'],\n",
    "                                                   test_size = 0.3, random_state = 156,\n",
    "                                                   stratify = df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=156)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state = 156, n_jobs = -1)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA weights2이용 랜덤포레스트 정확도: 0.28214873782080646\n"
     ]
    }
   ],
   "source": [
    "pred = rf_clf.predict(X_test)\n",
    "print('LDA weights2이용 랜덤포레스트 정확도:', accuracy_score(y_test, pred))\n",
    "    #정확도가 더 떨어짐\n",
    "    #오히려 토픽의 개수를 늘려야 정확도가 늘 수 있나?\n",
    "    #즉 현재의 토픽 개수는 차원을 줄이는 의미를 주는것이 아닌\n",
    "    #오히려 정보의 손실을 준다는 의미가 큰것\n",
    "    #9만개의 단어에 대한 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간: 3.42\n"
     ]
    }
   ],
   "source": [
    "#원래의 17개 카테고리로 토픽개수 설정해보기\n",
    "topic_num = 17\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "sk_lda = LatentDirichletAllocation(n_components = topic_num, n_jobs = -1)\n",
    "sk_lda_f = sk_lda.fit(cv_array)\n",
    "print('소요시간:', np.round((time.time() - start) / 60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_weights3 = sk_lda_f.transform(cv_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269242, 17)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_weights3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lda_weights3, df['category'],\n",
    "                                                   test_size = 0.3, random_state = 156,\n",
    "                                                   stratify = df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=156)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state = 156, n_jobs = -1)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA weights3이용 랜덤포레스트 정확도: 0.39159124955121144\n"
     ]
    }
   ],
   "source": [
    "pred = rf_clf.predict(X_test)\n",
    "print('LDA weights3이용 랜덤포레스트 정확도:', accuracy_score(y_test, pred))\n",
    "    #5%p 성장\n",
    "    #아직도 토픽의 개수가 충분치 않은것 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간: 11.42\n"
     ]
    }
   ],
   "source": [
    "#한번에 500개 정도로 늘려서 토픽을 설정해보기\n",
    "topic_num = 500\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "sk_lda = LatentDirichletAllocation(n_components = topic_num, n_jobs = -1)\n",
    "sk_lda_f = sk_lda.fit(cv_array)\n",
    "print('소요시간:', np.round((time.time() - start) / 60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_weights4 = sk_lda_f.transform(cv_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lda_weights4, df['category'],\n",
    "                                                   test_size = 0.3, random_state = 156,\n",
    "                                                   stratify = df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=156)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state = 156, n_jobs = -1)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA weights4이용 랜덤포레스트 정확도: 0.4768672700035903\n"
     ]
    }
   ],
   "source": [
    "pred = rf_clf.predict(X_test)\n",
    "print('LDA weights4이용 랜덤포레스트 정확도:', accuracy_score(y_test, pred))\n",
    "    #토픽의 개수를 1000개로 올리는것이 의미가 있나?\n",
    "    #현재 문서들이 2000개의 단어로 표현됨\n",
    "    #-> 거기서 1000개의 주제로 요약하는것은 사실상 단어 2개로 문서를 요약한다는 의미로 해석가능?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어표현을 5천개로 늘려서 1천개의 토픽으로 요약하기?\n",
    "cv = CountVectorizer(max_features = 5000, max_df = 0.80, min_df = 5).fit(df['cont_noun_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_array2 = cv.transform(df['cont_noun_str']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269242, 5000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_array2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간: 40.03\n"
     ]
    }
   ],
   "source": [
    "topic_num = 1000\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "sk_lda = LatentDirichletAllocation(n_components = topic_num, n_jobs = -1)\n",
    "sk_lda_f = sk_lda.fit(cv_array2)\n",
    "print('소요시간:', np.round((time.time() - start) / 60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_weights5 = sk_lda_f.transform(cv_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lda_weights5, df['category'],\n",
    "                                                   test_size = 0.3, random_state = 156,\n",
    "                                                   stratify = df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=156)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state = 156, n_jobs = -1)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA weights4이용 랜덤포레스트 정확도: 0.4822774937169599\n"
     ]
    }
   ],
   "source": [
    "pred = rf_clf.predict(X_test)\n",
    "print('LDA weights4이용 랜덤포레스트 정확도:', accuracy_score(y_test, pred))\n",
    "    #정확도 향상 의미가 없음. 중단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
